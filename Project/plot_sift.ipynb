{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harrisb002/CS_479/blob/Labs/plot_sift.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2iV3guznogw"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyYP4xQInogy"
      },
      "source": [
        "\n",
        "# SIFT feature detector and descriptor extractor\n",
        "\n",
        "This example demonstrates the SIFT feature detection and its description\n",
        "algorithm.\n",
        "\n",
        "The scale-invariant feature transform (SIFT) [1]_ was published in 1999 and is\n",
        "still one of the most popular feature detectors available, as its promises to\n",
        "be \"invariant to image scaling, translation, and rotation, and partially\n",
        "in-variant to illumination changes and affine or 3D projection\" [2]_. Its\n",
        "biggest drawback is its runtime, that's said to be \"at two orders of\n",
        "magnitude\" [3]_ slower than ORB, which makes it unsuitable for real-time\n",
        "applications.\n",
        "\n",
        "## References\n",
        ".. [1] https://en.wikipedia.org/wiki/Scale-invariant_feature_transform\n",
        "\n",
        ".. [2] D.G. Lowe. \"Object recognition from local scale-invariant\n",
        "       features\", Proceedings of the Seventh IEEE International\n",
        "       Conference on Computer Vision, 1999, vol.2, pp. 1150-1157.\n",
        "       :DOI:`10.1109/ICCV.1999.790410`\n",
        "\n",
        ".. [3] Ethan Rublee, Vincent Rabaud, Kurt Konolige and Gary Bradski\n",
        "       \"ORB: An efficient alternative to SIFT and SURF\"\n",
        "       http://www.gwylab.com/download/ORB_2012.pdf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "-yz8PI-Inogz",
        "outputId": "bab6174d-0bf0-4ecb-952c-071429bb487d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-be03953b9291>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdescriptor_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_and_extract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mkeypoints1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdescriptor_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeypoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mkeypoints1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mdescriptors1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdescriptor_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescriptors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from skimage import data\n",
        "from skimage import transform\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.feature import match_descriptors, plot_matches, SIFT\n",
        "\n",
        "img1 = rgb2gray(data.astronaut())\n",
        "img2 = transform.rotate(img1, 180)\n",
        "tform = transform.AffineTransform(scale=(1.3, 1.1), rotation=0.5,\n",
        "                                  translation=(0, -200))\n",
        "img3 = transform.warp(img1, tform)\n",
        "\n",
        "descriptor_extractor = SIFT()\n",
        "\n",
        "descriptor_extractor.detect_and_extract(img1)\n",
        "keypoints1 = descriptor_extractor.keypoints\n",
        "descriptors1 = descriptor_extractor.descriptors\n",
        "\n",
        "descriptor_extractor.detect_and_extract(img2)\n",
        "keypoints2 = descriptor_extractor.keypoints\n",
        "descriptors2 = descriptor_extractor.descriptors\n",
        "\n",
        "descriptor_extractor.detect_and_extract(img3)\n",
        "keypoints3 = descriptor_extractor.keypoints\n",
        "descriptors3 = descriptor_extractor.descriptors\n",
        "\n",
        "matches12 = match_descriptors(descriptors1, descriptors2, max_ratio=0.6,\n",
        "                              cross_check=True)\n",
        "matches13 = match_descriptors(descriptors1, descriptors3, max_ratio=0.6,\n",
        "                              cross_check=True)\n",
        "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(11, 8))\n",
        "\n",
        "plt.gray()\n",
        "\n",
        "plot_matches(ax[0, 0], img1, img2, keypoints1, keypoints2, matches12)\n",
        "ax[0, 0].axis('off')\n",
        "ax[0, 0].set_title(\"Original Image vs. Flipped Image\\n\"\n",
        "                   \"(all keypoints and matches)\")\n",
        "\n",
        "plot_matches(ax[1, 0], img1, img3, keypoints1, keypoints3, matches13)\n",
        "ax[1, 0].axis('off')\n",
        "ax[1, 0].set_title(\"Original Image vs. Transformed Image\\n\"\n",
        "                   \"(all keypoints and matches)\")\n",
        "\n",
        "plot_matches(ax[0, 1], img1, img2, keypoints1, keypoints2, matches12[::15],\n",
        "             only_matches=True)\n",
        "ax[0, 1].axis('off')\n",
        "ax[0, 1].set_title(\"Original Image vs. Flipped Image\\n\"\n",
        "                   \"(subset of matches for visibility)\")\n",
        "\n",
        "plot_matches(ax[1, 1], img1, img3, keypoints1, keypoints3, matches13[::15],\n",
        "             only_matches=True)\n",
        "ax[1, 1].axis('off')\n",
        "ax[1, 1].set_title(\"Original Image vs. Transformed Image\\n\"\n",
        "                   \"(subset of matches for visibility)\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DwQE-Yhro_9S"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}