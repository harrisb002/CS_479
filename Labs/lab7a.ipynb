{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harrisb002/CS_479/blob/Labs/lab7a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJ7DwYa2zZyS",
        "outputId": "d3255287-68cd-4a73-a1d2-b620edcbb9f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.13.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uYe1IPmD23k"
      },
      "source": [
        "## Credits\n",
        "Some of the material in this notebook has been taken from a Coursera Deep Learning course"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd4xI-PuD23m"
      },
      "source": [
        "## Learning Objectives\n",
        " - Construct simple deep learning models using the Keras Sequential model\n",
        " - Compile and fit Sequential models to data using various loss functions and optimisers\n",
        " - Evaluate models on held-out data and make model predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqvcxMNjzZyT"
      },
      "source": [
        "# The Sequential model API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-16O3b2zZyU"
      },
      "source": [
        " ## Coding sections\n",
        " #### [1. Building a Sequential model](#coding_tutorial_1)\n",
        " #### [2. Convolutional and pooling layers](#coding_tutorial_2)\n",
        " #### [3. The compile method](#coding_tutorial_3)\n",
        " #### [4. The fit method](#coding_tutorial_4)\n",
        " #### [5. The evaluate and predict methods](#coding_tutorial_5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTd-o9agzZyU"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_1\"></a>\n",
        "## Building a Sequential model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_hcGhEtD23o"
      },
      "source": [
        "### Import the different kinds of layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IE-C0DVizZyV"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Softmax\n",
        "from tensorflow.keras.utils import plot_model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iKoqxihOGPG5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gd8sruFzZyV"
      },
      "source": [
        "#### Build a feedforward neural network model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "H-OP92mizZyV"
      },
      "outputs": [],
      "source": [
        "# TODO 1\n",
        "# Build the Sequential feedforward neural network model.\n",
        "# A Flatten layer that takes as input of shape (28, 28)\n",
        "# 3 hidden layers,\n",
        "#     the first one with 32 units and sigmoid activation function\n",
        "#     the second and third with 16 units each and relu activation function\n",
        "# and an output layer with 10 classes\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Flatten (input_shape=(28,28)),\n",
        "    Dense(32, activation = 'sigmoid'),\n",
        "    Dense(16, activation = 'relu'),\n",
        "    Dense(16, activation = 'relu'),\n",
        "    Dense(10, activation = 'softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "7iBfkSGhFpjm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVi2I6LMD23q"
      },
      "source": [
        "Print the model summary to match with this:\n",
        "![](model1.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKFuzagc4Owz",
        "outputId": "88f17a35-6dd8-46bb-d271-ffd3372e251e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 784)\n",
            "(None, 32)\n",
            "(None, 16)\n",
            "(None, 16)\n",
            "(None, 10)\n"
          ]
        }
      ],
      "source": [
        "for layer in model.layers:\n",
        "    print(layer.output_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2ymPBOn15pj",
        "outputId": "83cbc17d-d28c-493d-c0c2-fad17830c093"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "model.output_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxBYO5h7zZyW",
        "outputId": "e15e5c34-07cf-496b-ce4a-6e404bb193bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                25120     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                272       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                170       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26090 (101.91 KB)\n",
            "Trainable params: 26090 (101.91 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Print the model summary\n",
        "#model.weights\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1BjHk-NzZyX"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_2\"></a>\n",
        "## Convolutional and pooling layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-9XThpfczZyX"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUlyrp59zZyX"
      },
      "source": [
        "####Â Build a convolutional neural network model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0-R3ZGGOzZyY"
      },
      "outputs": [],
      "source": [
        "# TODO 2\n",
        "# Build the Sequential convolutional neural network model.\n",
        "\n",
        "#Start with create a convolution layers with 16 layers, kernel size of 3, relu activation\n",
        "#and input shape of (28, 28, 1)\n",
        "\n",
        "#Next, add a max pooling layer of kernel size 3\n",
        "#Then, a flatten layer\n",
        "#Finally, a Dense layer with 10 units and softmax activation function\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Sequential([\n",
        "    Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D(3, 3),\n",
        "    Flatten(),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "FcGf2D4eGce-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW6CV98uD23u"
      },
      "source": [
        "Run model summary and obtain this:\n",
        "![](model2.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lGjYiEwYzZyY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f03fdfc6-0f69-49ff-ba0b-ada3e613fd63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                25120     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                272       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                170       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26090 (101.91 KB)\n",
            "Trainable params: 26090 (101.91 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Print the model summary\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76GSsVUcD23v"
      },
      "source": [
        "### Things to play with:\n",
        " - What happens if we remove the 1 in the `input_shape` parameter of `Conv2D` and just give (28, 28)?\n",
        " - how does the summary change if the convolution layer uses padding = 'SAME'?\n",
        " - how does the summary change if the convolution layer uses strides = 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8TylqtUzZyY"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_3\"></a>\n",
        "## The compile method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWAabLoYzZyZ"
      },
      "source": [
        "#### Compile the model\n",
        "\n",
        "Use the `adam` optimizer, `sparse categorical crossentropy` as the loss function, and `accuracy` and `mae` as the metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RJ17kkoZzZyZ"
      },
      "outputs": [],
      "source": [
        "# TODO 3: Define the model optimizer, loss function and metrics\n",
        "model.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    metrics = ['accuracy']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixdbaKyeD23x"
      },
      "source": [
        "### Things to play with:\n",
        " - What is the default learning rate of the [adam optimizer](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam)? Change it to 0.005.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "C71lPCiczZyZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e4738cb-2a4a-444b-e9ba-c6a841c3ce35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sparse_categorical_crossentropy\n",
            "<keras.src.optimizers.adam.Adam object at 0x793563e66c80>\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "# Print the resulting model attributes\n",
        "print(model.loss)\n",
        "print(model.optimizer)\n",
        "print(model.metrics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOyD6y1MzZyZ"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_4\"></a>\n",
        "## The fit method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Q0_8mAbszZyZ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5pe4xbEzZya"
      },
      "source": [
        "#### Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "z4-vOOgUzZya",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "863735b1-1bbe-4118-d059-839396852fcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load the Fashion-MNIST dataset\n",
        "\n",
        "fashion_mnist_data = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist_data.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "60uqvs0pzZya",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f41fa27e-c1fd-4b92-e7c5-b8bd60240b56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "# TODO 4: Print the shape of the training data and training labels\n",
        "print(train_images.shape)\n",
        "print(test_images.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ct6-faQazZya",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0351f57e-17d7-459e-d2e4-215e12cc8226"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ],
      "source": [
        "# Define the labels\n",
        "\n",
        "labels = [\n",
        "    'T-shirt/top',\n",
        "    'Trouser',\n",
        "    'Pullover',\n",
        "    'Dress',\n",
        "    'Coat',\n",
        "    'Sandal',\n",
        "    'Shirt',\n",
        "    'Sneaker',\n",
        "    'Bag',\n",
        "    'Ankle boot'\n",
        "]\n",
        "print(train_labels[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1xb3aAe5zZya"
      },
      "outputs": [],
      "source": [
        "# TODO 5: Rescale the values in train_images and test_image so that they lie in between 0 and 1.\n",
        "train_images = train_images/255.\n",
        "test_images = test_images/ 255.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "2ASkSRwRzZyb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "13e1de11-07fc-4099-a91c-421cd823bd3c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: Pullover\n"
          ]
        }
      ],
      "source": [
        "# Display one of the training images randomly (Run this cell several times to see different images)\n",
        "i =  np.random.choice(train_images.shape[0])\n",
        "img = train_images[i, :, :]\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "print(\"Label:\", labels[train_labels[i]])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Gsk795IDN7UG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWc5SdImzZyb"
      },
      "source": [
        "#### Fit the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0wrIOGRzZyb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f90e34a7-b082-4b66-aff9-a87927a1ede1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "1875/1875 [==============================] - 15s 7ms/step - loss: 0.6285 - accuracy: 0.7850\n",
            "Epoch 2/8\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4064 - accuracy: 0.8542\n",
            "Epoch 3/8\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3735 - accuracy: 0.8647\n",
            "Epoch 4/8\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3535 - accuracy: 0.8733\n",
            "Epoch 5/8\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3385 - accuracy: 0.8775\n",
            "Epoch 6/8\n",
            "1669/1875 [=========================>....] - ETA: 0s - loss: 0.3269 - accuracy: 0.8804"
          ]
        }
      ],
      "source": [
        "# TODO 6: Fit the model using 8 epochs and batch size of 256. Store the output in variable called history\n",
        "# NOTE: If training is taking long, use less number of epochs or a portion of the training set\n",
        "history = model.fit(train_images, train_labels, epochs=8)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbVf2TudD234"
      },
      "source": [
        "**SUPER DUPER IMPORTANT NOTE** If you run the above cell again, the training will resume from where it stopped the last time! To restart the training with default weights, re-create the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uX2N-SpYD234"
      },
      "source": [
        "### Things to play with:\n",
        " - How does the training proceed if the `batch_size` is reduced? How does that impact the accuracy/mae?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-J5ca-WzZyb"
      },
      "source": [
        "#### Plot training history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKcHdJXHzZyb"
      },
      "outputs": [],
      "source": [
        "# Load the history into a pandas Dataframe\n",
        "# Very useful to check how training is going\n",
        "\n",
        "df = pd.DataFrame(history.history)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTMVU8MRzZyb"
      },
      "outputs": [],
      "source": [
        "# Make a plot for the loss\n",
        "\n",
        "loss_plot = df.plot(y=\"loss\", title = \"Loss vs. Epochs\", legend = False)\n",
        "loss_plot.set(xlabel=\"Epochs\", ylabel=\"Loss\")\n",
        "#loss_plot = df.plot(y=\"loss\", title = \"Loss vs. Epochs\", legend = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uq6To9FKzZyc"
      },
      "outputs": [],
      "source": [
        "# Make a plot for the accuracy\n",
        "acc_plot = df.plot(y=\"accuracy\", title = \"Accuracy vs. Epochs\", legend = False)\n",
        "acc_plot.set(xlabel=\"Epochs\", ylabel=\"Accuracy\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UY-ueOlszZyc"
      },
      "outputs": [],
      "source": [
        "# TODO 7: Make a plot for the additional metric (mae)\n",
        "acc_plot = df.plot(y=\"mae\", title = \"Mae vs. Epochs\", legend = False)\n",
        "acc_plot.set(xlabel=\"Epochs\", ylabel=\"Mae\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8tKf2ozzZyc"
      },
      "source": [
        "***\n",
        "<a id=\"coding_tutorial_5\"></a>\n",
        "## The evaluate and predict methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xE3rfvwFzZyc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6C98WrGNzZyc"
      },
      "source": [
        "#### Evaluate the model on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxZFyoKxzZyc"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_accuracy, test_mae = model.evaluate(test_images, test_labels, verbose=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alGhIroNzZyc"
      },
      "source": [
        "#### Make predictions from the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIgj9-A_zZyc"
      },
      "outputs": [],
      "source": [
        "# Choose a random test image\n",
        "\n",
        "random_inx = np.random.choice(test_images.shape[0])\n",
        "\n",
        "test_image = test_images[random_inx]\n",
        "plt.imshow(test_image)\n",
        "plt.show()\n",
        "print(f\"Label: {labels[test_labels[random_inx]]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yK_bACAczZyd"
      },
      "outputs": [],
      "source": [
        "# TODO 8: Get the model predictions on the above image\n",
        "pred = #FIX ME\n",
        "print(\"Prediction: \", labels[np.argmax(pred)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxr8ZSxKLmkk"
      },
      "outputs": [],
      "source": [
        "# TODO 9: Extend the above code to predict labels for k random test images\n",
        "\n",
        "def get_random_set(k):\n",
        "    '''\n",
        "    Returns a numpy array containing k random images from test_images: shape is (k, 28, 28)\n",
        "    and a numpy array containing corresponding labels from test_labels: shape is (k,)\n",
        "    '''\n",
        "    #Strategy 1: Create an empty numpy array of the correct size and initialize each row to be a random test image\n",
        "    #Strategy 2: Create an empty list, append k random test images. Then convert to numpy array.\n",
        "    #Strategy 3: Construct a numpy array containing k random but unique indices. Slice the test_images and test_labels using these indices.\n",
        "    pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOpA4Ef8D23_"
      },
      "outputs": [],
      "source": [
        "test_set, test_lab = get_random_set(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HN97ETAdNjIH"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Print the shape of the test set and test labels\n",
        "print(test_set.shape)\n",
        "print(test_lab.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQ1Fo63XNatN"
      },
      "outputs": [],
      "source": [
        "# Get the model predictions for all the random images and compare with ground truth\n",
        "\n",
        "pred = model.predict(test_set)\n",
        "print(pred.shape)\n",
        "for i, elem in enumerate(pred):\n",
        "    print(\"Ground Truth: \", labels[test_lab[i]], end = \";\")\n",
        "    print(\"Prediction: \", labels[np.argmax(elem)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvZfgzWwTFOP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}