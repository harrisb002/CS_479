{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhRtDu6vbHWTbuHt3PYKdL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harrisb002/CS_479/blob/Week-6/Deep_Learning_Notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.3blue1brown.com/topics/neural-networks"
      ],
      "metadata": {
        "id": "mvc6LzwCu61a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Chapter 1: Deep learning\n",
        "\n",
        "This lesson is all about motivating and understanding the structure and mathematical description of a neural network, while the next lesson will focus on how to train it with labeled examples."
      ],
      "metadata": {
        "id": "cfzAa2E4n0zw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How Information Passes Between Layers:\n",
        "The goal is to have some mechanism that could conceivably combine pixels into edges, or edges into patterns, or patterns into digits. It would be especially elegant if all of those different steps used the same mathematical procedure.\n",
        "- Assign a weight to each of the connections between our neuron and the neurons from the first layer. These weights are just numbers.\n",
        "- If the neuron in the first layer is on, then a positive weight suggests that the neuron in the second layer should also be on, and a negative weight suggests that the neuron in the second layer should be off.\n",
        "- So to actually compute the value of this second-layer neuron, you take all the activations from the neurons in the first layer, and compute their weighted sum.\n",
        " - $w_{0}$$a_{0}$ + $w_{1}$$a_{1}$ + ... $w_{n}$$a_{n}$\n"
      ],
      "metadata": {
        "id": "FD1HEkIFoDmD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sigmoid ( ùúé ) Squishification (Normalization): The result of the weighted sum like this can be any number, but for this network we want the activations to be values between 0 and 1. So it‚Äôs common to pump this weighted sum into some function that squishes the real number line into the range between 0 and 1.\n",
        "- One common function that does this is called the ‚Äúsigmoid‚Äù function, also known as a logistic curve, which we represent using the symbol\n",
        "œÉ. Very negative inputs end up close to 0, very positive inputs end up close to 1, and it steadily increases around 0. So the activation of the neuron here will basically be a measure of how positive the weighted sum is."
      ],
      "metadata": {
        "id": "VUkHKVFeo5Yz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "More Compact Notation:\n",
        "- First, organize all the activations from the first layer into a column vector.\n",
        "- Next, organize all the weights as a matrix, where each row of this matrix corresponds to all the connections between neurons in the first layer and a particular neuron in the next layer.\n",
        "- Then the product $Wa^{0}$ is a column vector containing all the weighted sums for the neurons in the next layer\n",
        "- Instead of talking about adding the bias to each one of these values independently, we represent it by organizing all those biases into a vector, and adding the entire vector to the previous matrix-vector product:\n",
        " - $b_{0}$ Is the bias\n",
        "\n",
        "- $a_{0}{^1}$ = ùúé ($w_{0,0}$ $a_{0}{^0}$+ $w_{0,1}$ $a_{1}{^1}$ + ... $w_{0,n}$ $a_{n}{^n}$ - $b_{0}$ )"
      ],
      "metadata": {
        "id": "PPGS6bLzrUDa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 2: Gradient descent\n",
        "The above explores the structure of a neural network. Now, let‚Äôs talk about how the network learns by seeing many labeled training data.\n",
        "\n",
        "The core idea is a method known as gradient descent, which underlies not only how neural networks learn, but a lot of other machine learning as well.\n",
        "\n",
        "The activation for each neuron in the following layers is based on a weighted sum of all activations from the previous layer, plus some number called the ‚Äúbias.‚Äù We then wrap a nonlinear function around this sum, such as a sigmoid or a ReLU."
      ],
      "metadata": {
        "id": "ny_7Qy9yr20a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How the Network Learns: It really just comes down to finding the minimum of a specific function.\n"
      ],
      "metadata": {
        "id": "iRNLOqRDvARc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Cost Function: Remember, our network's behavior is determined by all of its weights and biases. The weights represent the strength of connections between each neuron in one layer and each neuron in the next. And each bias is an indication of whether its neuron tends to be active or inactive.\n",
        "- Add up the squares of the differences between each of the 'bad' output activations and the values you want them to have. We‚Äôll call this the \"cost\" of a single training example.\n",
        " - The cost is small when the network confidently classifies this image correctly but large when it doesn‚Äôt know what it‚Äôs doing.\n",
        " - To really measure its performance, we need to consider the average cost over all the tens of thousands of training examples."
      ],
      "metadata": {
        "id": "soA9ceWevcA6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, the network itself is a function. It has 784 inputs (the pixel values), 10 outputs, and 13,002 parameters.\n",
        "\n",
        "The inputs of the cost function are those 13,002 weights and biases, and it spits out a single number describing how bad those weights and biases are. It‚Äôs defined in terms of the network‚Äôs behavior on all the tens of thousands of pieces of labeled training data. In other words, this training data is a massive set of parameters to the cost function.\n"
      ],
      "metadata": {
        "id": "WFsIemFXwKB7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Minimizing the Cost Function using The Gradient:\n",
        "We need to use a vector to represent the direction of steepest ascent.\n",
        "\n",
        "- This vector is called the ‚Äúgradient‚Äù, and it tells you which direction you should step to increase the function most quickly.\n",
        "\n",
        "- Naturally enough, taking the negative of that vector gives you the direction to step which decreases the function most quickly. What‚Äôs more, the length of that gradient vector is an indication for just how steep that steepest slope is.\n",
        "\n",
        "- So the algorithm for minimizing this function is to compute this gradient direction, take a step downhill, and repeat that over and over. This process is called ‚Äúgradient descent.‚Äù"
      ],
      "metadata": {
        "id": "XSclv7v1wc_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The negative gradient is a vector direction in this insanely huge input space that tells you what nudges to those 13,002 numbers would cause the most rapid decrease to the cost function.\n",
        "\n",
        "Each component of the negative gradient vector tells us two things. The sign, of course, tells us whether the corresponding component of the input vector should be nudged up or down. But importantly, the relative magnitudes of the components in this gradient tells us which of those changes matters more."
      ],
      "metadata": {
        "id": "F5hpsAi7xN4s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Big Idea:\n",
        "- A network ‚Äúlearning‚Äù, means changing the weights and biases to minimize a cost function, which improves the network's performance on the training data"
      ],
      "metadata": {
        "id": "ML5_jpFuxcZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The algorithm for computing the value of this gradient vector efficiently is called backpropagation."
      ],
      "metadata": {
        "id": "JuS3wbQRxWvv"
      }
    }
  ]
}